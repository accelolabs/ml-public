# Supervised.

## 1. Чем обучение с учителем отличается от обучения без учителя? Какое отношение оно имеет к кластеризации, классификации, регрессии, ранжирования, генерации?
**Обучение с учителем** подразумевает то, что ответы для каждого объекта обучающей выборки заранее известны. Оно включает такие задачи как регрессия, классификация, ранжирование.
- **Регрессия** - Предсказание численного признака. Например, предсказание стоимости поездки на такси.
- **Классификация** - Предсказание принадлежности объекта к конечному количеству заранее определенных классов.
- **Ранжирование** - Предсказание элемента конечного (частично-) упорядоченного множества. Например, сортировка документов по релевантности.
- **Генерация** - Создание похожих объектов на основе существующих. Например, написание текста.

**Обучение без учителя** подразумевает то, что готовых ответов нет. Оно включает такие задачи как кластеризация.
- **Кластеризация** - Разбиение набора данных на кластеры по похожим признакам.


## 2. Что такое параметры модели? Что такое гиперпараметры?

**Параметры** - Настраиваемые в процессе обучения модели коэффициенты, которые влияют на прогнозы.

**Гиперпараметры** - Характеристики модели, фиксируемые до начала обучения. Влияют на структуру модели и процесс обучения. У модели может не быть гиперпараметров.


## 3. Как и зачем перебирать гиперпараметры?
**Перебор гиперпараметров** нужен для увеличения качества работы модели. Единственно правильного варианта подбирать гиперпараметры нет, но может использоваться Grid Search, Random Search и эмпирические методы (наугад). Grid Search более полезен, когда параметров немного, а модель обучается быстро.
- Grid Search это перебор всех заданных комбинаций гиперпараметров.
- Random Search это перебор всех случайно выбранных комбинаций гиперпараметров.
- Эмпирический метод это когда ты находишь уже готовые гиперпараметры и производишь Random Search руками.


## 4. Что такое мягкая классификация?
**Мягкая классификация** - классификация, при которой объекту присваиваются вероятности принадлежности к классам. Вместо единичного класса модель возвращает вектор вероятностей для каждого класса.


## 5. Что такое переобучение?
**Переобучение** - Явление, при котором модель избыточно подстраивается под данные, при этом теряя способность генерализировать закономерности в реальных данных.


## 6. Что такое бейзлайн? Что такое наивный алгоритм? Какие примеры наивных алгоритмов можно привести для задач классификации и регрессии?
**Бейзлайн** - простое базовое быстрое решение, с которым сравниваются разработанные модели. Модель должна быть значительно лучше бейзлайна.

**Наивный алгоритм** - baseline, в котором уделяется внимание какому-либо правилу датасета.


## 7. Как и зачем дискретизировать, бинаризовать, нормализовывать и взвешивать признаки?
**Дискретизация** - разделение диапазона на несколько конечных интервалов. Нужна для упрощения структуры данных или перехода от непрерывных атрибутов к категориальным.

**Бинаризация** - Преобразование категории из $n$ значений в $n$ бинарных категорий или $n$ бинарных значений. Используется для перехода от категориальных атрибутов к численным значениям.

**Нормализация** - Приведение значений к численной вероятности. Требуется для того, чтобы признаки с большим разбросом не замедляли сходимость.

**Взвешивание** - Придание разного веса отдельным признакам или объектам. Взвешивание помогает улучшить качество модели за счет эмпирических наблюдений (признаки), исправления дисбаланса классов (объекты). Чем больше вес объекта или признака, тем больше он влияет на результат обучения.


## 8. Как и зачем делать one-hot encoding? Можно ли это делать функцией pandas.get_dummies? Чем one-hot отличается от binary-encoding?



## 9. Как вычисляется cross-entropy и почему она cross?


## 10. Зачем делить данные на train, test, val? Чем val отличается от test? Кросс-валидация, ее виды. Что такое data leak?


## 11. Что такое регуляризация? Как устроены L1 и L2 регуляризации?


## 12. Метрики классификации: precision, recall, accuracy, F1, F-beta, roc auc кривая, precision-recall кривая и как они строится, confusion matrix.


## 13. Метрики регрессии: mae, mse, (s-)mape.


## 14. Вопрос-приз: можно ли использовать модели машинного обучения для заполнения пропущенных данных в датасете?
Мне таких призов не надо, думайте сами.

## 15. Дисбаланс классов: как влияет на метрики и модели, как с этим справиться?


## 16. Градиентный спуск. Как оптимизирует параметры моделей, что такое пространство ошибок, чем отличаются (мини-)батчевый и стохастический?


## 17. Модель линейная регрессия.


## 18. Модель логистическая регрессия.


## 19. Модель дерево решений, модель случайный лес. Как считается важность признаков в дереве?


## 20. Ансамблирование алгоритмов. Бустинг.


## Источники.
- Большая часть информации взята из ноушена flying-open-687.
- Хэндбук Яндекса.
- Моя шиза.
- ChatGpt-5 mini использовался, потому что я отупел и разучился писать.
